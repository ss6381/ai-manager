{
    ".gitignore": ".env\n__pycache__/\n*.pyc\n*.pyo\nvenv/\nclient_secrets.json",
    "Lecture_Notes.txt": "**Lecture Notes: Introduction to Machine Learning**\n\n**Date:** October 10, 2024\n**Duration:** 45 minutes\n**Speaker:** Professor Smith\n\n**Key Concepts:**\n\n1. **Machine Learning**: A subset of artificial intelligence that enables machines to learn from data and make decisions or predictions based on that data.\n2. **Types of Machine Learning**:\n\t* **Supervised Learning**: Training a model on labeled data, where each example includes the correct answer.\n\t* **Unsupervised Learning**: Training a model on unlabeled data, where the model finds patterns or structures on its own.\n\t* **Reinforcement Learning**: An agent learns by interacting with an environment and receiving rewards or penalties based on its actions.\n\n**Important Points:**\n\n1. **Supervised Learning**:\n\t* Involves training a model on labeled data.\n\t* Example: Teaching a child to recognize objects by showing them pictures and saying what they are.\n\t* Application: Facial recognition systems.\n2. **Unsupervised Learning**:\n\t* Involves training a model on unlabeled data.\n\t* Example: Clustering, where a child groups objects based on similar features.\n\t* Application: Customer segmentation, where companies group customers based on purchasing behavior.\n3. **Reinforcement Learning**:\n\t* Involves an agent learning by interacting with an environment and receiving rewards or penalties.\n\t* Example: Training a pet, where it learns which actions are associated with rewards.\n\t* Application: Robotics, where robots learn to navigate environments, and complex games where AI can beat human players.\n\n**Relevant Details:**\n\n1. **Machine Learning Applications**: Vast applications across industries, including healthcare, finance, and more.\n2. **Demand for Skilled Professionals**: The demand for skilled professionals in machine learning continues to grow.\n3. **Real-World Examples**: Facial recognition systems, customer segmentation, robotics, and complex games.\n\n**Key Takeaways:**\n\n1. Machine Learning enables machines to learn from data and make decisions or predictions.\n2. There are three primary types of machine learning: Supervised Learning, Unsupervised Learning, and Reinforcement Learning.\n3. Each type of machine learning has its own applications and real-world examples.\n4. The demand for skilled professionals in machine learning is growing.\n\n**Study Tips:**\n\n1. Review the definitions of Supervised Learning, Unsupervised Learning, and Reinforcement Learning.\n2. Understand the differences between each type of machine learning.\n3. Familiarize yourself with real-world applications of each type of machine learning.\n4. Practice identifying which type of machine learning is used in a given scenario.",
    "app.py": "import os\nimport base64\nimport requests\nimport spacy\nfrom flask import Flask, request, jsonify\nfrom dotenv import load_dotenv\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.models import PointStruct, VectorParams\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import pipeline\nfrom chatgroq_handler import call_groq_api\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom llama_index.core.indices.vector_store.base import VectorStoreIndex\nfrom llama_index.core import Document\nfrom llama_index.core.settings import Settings\nfrom google_drive_upload import save_notes_to_drive\n\n# Disable OpenAI LLM globally\nSettings.llm = None\n\n# Load environment variables\nload_dotenv()\n\n# Initialize Flask app, spaCy model, Qdrant client, and Sentence Transformer model\napp = Flask(__name__)\nnlp = spacy.load(\"en_core_web_sm\")\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\nqdrant_client = QdrantClient(host=\"localhost\", port=6333)\n\n# Initialize Hugging Face embedding model\nhuggingface_embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n\n# Fireworks AI configuration\nfireworks_api_key = os.getenv(\"FIREWORKS_API_KEY\")\nfireworks_model_endpoint = \"https://api.fireworks.ai/inference/v1/chat/completions\"\n\n# Initialize summarization pipeline\nsummarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n\n# Store user quiz answers and correct answers in a list\nuser_quiz_answers = {}\ncurrent_correct_answer = []\npoll_rating = {}\n\n# Function to generate embeddings\ndef embed_text(text):\n    return model.encode(text)\n\n# Function to store lecture transcript in Qdrant and LlamaIndex\ndef store_transcript(file_path):\n    try:\n        with open(file_path, \"r\") as file:\n            transcript_text = file.read()\n\n        # Split transcript for both Qdrant and LlamaIndex\n        max_chunk_size = 512\n        transcript_chunks = [transcript_text[i:i + max_chunk_size] for i in range(0, len(transcript_text), max_chunk_size)]\n        embeddings = [embed_text(chunk) for chunk in transcript_chunks]\n\n        # Store in Qdrant\n        if qdrant_client.collection_exists(collection_name=\"lecture_transcripts\"):\n            qdrant_client.delete_collection(collection_name=\"lecture_transcripts\")\n\n        qdrant_client.create_collection(\n            collection_name=\"lecture_transcripts\",\n            vectors_config=VectorParams(size=len(embeddings[0]), distance=\"Cosine\")\n        )\n\n        points = [PointStruct(id=i, vector=embedding, payload={\"text\": chunk}) for i, (chunk, embedding) in enumerate(zip(transcript_chunks, embeddings))]\n        qdrant_client.upsert(collection_name=\"lecture_transcripts\", points=points)\n        print(\"Transcript stored in Qdrant successfully.\")\n        \n        # Store in LlamaIndex using from_documents\n        documents = [Document(text=chunk) for chunk in transcript_chunks]\n        global llama_index\n        llama_index = VectorStoreIndex.from_documents(documents, embed_model=huggingface_embed_model)\n        print(\"Transcript stored in LlamaIndex successfully.\")\n    except Exception as e:\n        print(\"An error occurred while storing transcript:\", e)\n\n# Function to query Qdrant for relevant lecture chunks\ndef query_qdrant_for_summary(query_text):\n    query_vector = embed_text(query_text)\n    search_result = qdrant_client.search(\n        collection_name=\"lecture_transcripts\",\n        query_vector=query_vector,\n        limit=5\n    )\n    combined_text = \" \".join([hit.payload[\"text\"] for hit in search_result])\n    return combined_text\n\n# Function to query LlamaIndex for relevant content\ndef query_llamaindex_for_summary(query_text):\n    query_engine = llama_index.as_query_engine(llm=None)\n    response = query_engine.query(query_text)\n    \n    # Assuming response contains the result text directly\n    combined_text = response.response  # Adjust based on actual attribute\n    return combined_text\n\n# Function to generate a summary using both Qdrant and LlamaIndex\ndef generate_summary_with_llamaindex(query_text):\n    relevant_text = query_llamaindex_for_summary(query_text)\n    return generate_summary(relevant_text)\n\n# Function to generate a summary for a given text\ndef generate_summary(text):\n    max_chunk = 512\n    text_chunks = [text[i:i + max_chunk] for i in range(0, len(text), max_chunk)]\n    \n    summary = \"\"\n    for chunk in text_chunks:\n        summary_chunk = summarizer(chunk, max_length=min(150, max(30, int(len(chunk) * 0.5))), min_length=30, do_sample=False)\n        summary += summary_chunk[0]['summary_text'] + \" \"\n    \n    return summary.strip()\n\n# Function to generate a quiz question using Fireworks API\ndef generate_quiz_with_fireworks(summary_text):\n    headers = {\n        \"Authorization\": f\"Bearer {fireworks_api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n    \n    data = {\n        \"model\": \"accounts/fireworks/models/llama-v3p1-405b-instruct\",\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": f\"Generate a multiple-choice quiz question based on the following content:\\n\\n{summary_text}\"\n            }\n        ]\n    }\n    \n    response = requests.post(fireworks_model_endpoint, json=data, headers=headers)\n    if response.status_code == 200:\n        result = response.json()\n        question_text = result.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\").strip()\n        \n        if \"Correct answer:\" in question_text:\n            question, correct_answer = question_text.split(\"Correct answer:\")\n            question = question.strip()\n            correct_answer = correct_answer.strip().split(\")\")[0]\n            current_correct_answer.clear()\n            current_correct_answer.append(correct_answer)\n            return question\n        else:\n            return \"Unable to generate a question at this time.\"\n    else:\n        return \"Unable to generate a question at this time.\"\n    \ndef generate_notes_with_fireworks(transcript_file):\n    # Read the transcript file\n    try:\n        with open(transcript_file, \"r\") as file:\n            transcript_text = file.read()\n    except FileNotFoundError:\n        print(f\"Error: The file {transcript_file} was not found.\")\n        return None\n\n    # Prepare the data payload\n    data = {\n        \"model\": \"accounts/fireworks/models/llama-v3p1-405b-instruct\",\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": (\n                    \"Create detailed lecture notes based on the following transcript. \"\n                    \"Include important points, key concepts, and any relevant details that will help with studying:\\n\\n\" +\n                    transcript_text\n                )\n            }\n        ]\n    }\n\n    headers = {\n        \"Authorization\": f\"Bearer {fireworks_api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    # Send the request to Fireworks AI\n    try:\n        response = requests.post(fireworks_model_endpoint, json=data, headers=headers)\n        response.raise_for_status()\n        notes_content = response.json().get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\").strip()\n        return notes_content\n    except requests.exceptions.RequestException as e:\n        print(f\"Error generating notes with Fireworks AI: {e}\")\n        return None\n\ndef get_topic_and_resources_with_llm(summary_text):\n    headers = {\n        \"Authorization\": f\"Bearer {fireworks_api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n    \n    data = {\n        \"model\": \"accounts/fireworks/models/firefunction-v2\",\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": (\n                    f\"Based on the following lecture content, identify the main topic \"\n                    f\"and provide a list of relevant educational resources such as articles, \"\n                    f\"videos, or books to help a student learn more about it. \"\n                    f\"Please follow this exact format:\\n\\n\"\n                    f\"Main Topic: [Topic Name]\\n\"\n                    f\"Resources:\\n\"\n                    f\"1) [Resource Title] - [Description]\\n\"\n                    f\"2) [Resource Title] - [Description]\\n\\n\"\n                    f\"Lecture Content:\\n{summary_text}\"\n                )\n            }\n        ]\n    }\n    \n    response = requests.post(fireworks_model_endpoint, json=data, headers=headers)\n    if response.status_code == 200:\n        result = response.json()\n        response_text = result.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\").strip()\n#        print(\"Fireworks API response:\", response_text)  # Debugging output to inspect response\n\n        # Extract the main topic and resources\n        lines = response_text.splitlines()\n        topic = \"\"\n        resources = []\n\n        # Process each line to detect topic and resource items\n        for line in lines:\n            line = line.strip()\n            if line.startswith(\"Main Topic:\"):\n                # Extract topic text after \"Main Topic:\"\n                topic = line.replace(\"Main Topic:\", \"\").strip()\n            elif line.startswith((\"1)\", \"2)\", \"3)\", \"4)\", \"5)\")):\n                # Append the resource text after the numeric label\n                resource_text = line.split(\")\", 1)[-1].strip()\n                if resource_text:\n                    resources.append(resource_text)\n\n        # Ensure topic and resources have valid content\n        if not topic:\n            topic = \"Unknown Topic\"\n        if not resources:\n            resources = [\"No resources found for this topic.\"]\n            \n        return topic, resources\n    else:\n        print(\"Error with Fireworks API:\", response.status_code, response.text)\n        return None, None\n\n\n# Function to get Zoom bot token\ndef get_zoom_bot_token():\n    client_id = os.getenv(\"ZOOM_CLIENT_ID\")\n    client_secret = os.getenv(\"ZOOM_CLIENT_SECRET\")\n    token_url = \"https://zoom.us/oauth/token?grant_type=client_credentials\"\n    \n    headers = {\n        \"Authorization\": \"Basic \" + base64.b64encode(f\"{client_id}:{client_secret}\".encode()).decode()\n    }\n    \n    response = requests.post(token_url, headers=headers)\n    return response.json().get(\"access_token\") if response.status_code == 200 else None\n\n# Handle Zoom webhook commands\ndef handle_zoom_webhook(payload):\n    zoom_bot_jid = os.getenv(\"ZOOM_BOT_JID\")\n    auth_token = get_zoom_bot_token()\n    \n    payload_data = payload.get(\"payload\", {})\n    command_text = payload_data.get(\"cmd\", \"\").lower()\n    to_jid = payload_data.get(\"toJid\")\n    account_id = payload_data.get(\"accountId\")\n\n    if not to_jid or not account_id:\n        print(\"Error: 'toJid' or 'accountId' is missing in the payload\")\n        return \"Error: Missing required fields in the payload\"\n\n    response_text = \"Command not recognized. Try '/summarize lecture' or '/start quiz'.\"\n\n    if \"/summarize lecture\" in command_text:\n        summary = generate_summary_with_llamaindex(\"lecture summary\")\n        response_text = f\"Lecture Summary:\\n{summary}\"\n    elif \"/start quiz\" in command_text:\n        summary = generate_summary_with_llamaindex(\"lecture summary\")\n        question_text = generate_quiz_with_fireworks(summary)\n        response_text = f\"Quiz Question:\\n{question_text}\"\n    elif \"/answer\" in command_text:\n        answer_given = command_text.split(\"/answer\")[-1].strip().upper()\n        correct_answer = current_correct_answer[-1].upper()\n        response_text = \"Correct answer!\" if answer_given == correct_answer else \"Incorrect answer. Try again.\"\n    elif \"/additional resources\" in command_text:\n        # Generate a lecture summary to use for topic and resource extraction\n        summary = generate_summary_with_llamaindex(\"lecture summary\")\n        topic, resources = get_topic_and_resources_with_llm(summary)\n        \n        # Format the response text for Zoom bot\n        if resources:\n            response_text = f\"**Main Topic:** {topic}\\n\\n**Additional Resources:**\\n\" + \"\\n\".join([f\"{i+1}. {res}\" for i, res in enumerate(resources)])\n        else:\n            response_text = \"Sorry, no additional resources found for this topic.\"\n    elif \"/poll\" in command_text:\n        response_text = \"On a scale of 1-5, how well did you understand the lecture? Please respond with '/rate <number>'.\"\n    elif command_text.startswith(\"/rate\"):\n        try:\n            # Extract rating from the command\n            rating = int(command_text.split(\"/rate\")[-1].strip())\n            if 1 <= rating <= 5:\n                poll_rating[to_jid] = rating  # Store rating with user's JID\n                response_text = f\"Thank you! You rated the lecture with a {rating} out of 5.\"\n            else:\n                response_text = \"Please enter a valid rating between 1 and 5.\"\n        except ValueError:\n            response_text = \"Invalid rating. Please respond with a number between 1 and 5.\"\n    elif \"/generate notes\" in command_text:\n        # Generate notes from the transcript file\n        transcript_file = \"transcripts/transcript_intro_to_ml.txt\"\n        notes = generate_notes_with_fireworks(transcript_file)\n        if notes:\n            save_notes_to_drive(notes, filename=\"Lecture_Notes.txt\", folder_id = \"1lcClr2x2N2v8iQcSPEXrlgVnXGB6Ym7d\")\n            response_text = \"Notes generated successfully, sent to Zoom chat, and saved to Google Drive.\"\n        else:\n            response_text = \"Failed to generate notes from the transcript.\"\n    else:\n        response_text = call_groq_api(command_text, to_jid)\n\n    # Prepare message payload for Zoom\n    message_payload = {\n        \"robot_jid\": zoom_bot_jid,\n        \"to_jid\": to_jid,\n        \"user_jid\": to_jid,\n        \"account_id\": account_id,\n        \"content\": {\n            \"head\": {\"text\": \"Meeting Insights - Response\"},\n            \"body\": [{\"type\": \"message\", \"text\": response_text}]\n        }\n    }\n    \n    headers = {\n        \"Authorization\": f\"Bearer {auth_token}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    # Send the message to Zoom\n    zoom_url = \"https://api.zoom.us/v2/im/chat/messages\"\n    response = requests.post(zoom_url, headers=headers, json=message_payload)\n    print(\"Message sent successfully to Zoom:\", response.json() if response.status_code == 201 else response.json())\n\n@app.route('/webhook', methods=['POST'])\ndef zoom_webhook():\n    payload = request.json\n    handle_zoom_webhook(payload)\n    return jsonify({\"status\": \"Processed\"}), 200\n\nif __name__ == '__main__':\n    store_transcript(\"transcripts/transcript_intro_to_ml.txt\")\n    app.run(host='0.0.0.0', port=int(os.getenv(\"PORT\", 4000)))\n",
    "chatgroq_handler.py": "import os\nfrom langchain_groq import ChatGroq\nfrom langchain_core.prompts import PromptTemplate\nfrom send_zoom_message import send_chat_to_zoom\nfrom dotenv import load_dotenv\n\n# Load environment variables\nload_dotenv()\n\n# Initialize ChatGroq with your API key and model\nchat = ChatGroq(\n    temperature=0,\n    groq_api_key=os.getenv(\"GROQ_API_KEY\"),\n    model_name=\"llama-3.1-70b-versatile\"\n)\n\n# Keep conversation history to maintain context with the user\nconversation_history = {}\n\ndef call_groq_api(command_text, to_jid):\n    try:\n        # Directly use the command_text as the prompt without history\n        new_user_prompt = f\"Human: {command_text}\\n\\nAssistant:\"\n\n        # Set up the prompt template for ChatGroq\n        prompt_template = PromptTemplate.from_template(\n            \"\"\"\n            You are a helpful assistant. Respond to each user prompt as follows:\n            ### HUMAN INPUT:\n            {prompt}\n\n            ### ASSISTANT:\n            \"\"\"\n        )\n\n        # Send only the new prompt to ChatGroq\n        chain = prompt_template | chat\n        res = chain.invoke(input={\"prompt\": new_user_prompt})\n\n        # Process the response\n        completion = res.content.strip()\n\n        # Optionally: update conversation history (if needed for future interactions)\n        conversation_history[to_jid] = new_user_prompt + completion\n\n        return completion\n    except Exception as e:\n        print(f\"Error calling Groq API: {e}\")\n        return \"Sorry, something went wrong while processing your request.\"\n",
    "embedding_utils.py": "from transformers import AutoTokenizer, AutoModel\nimport torch\n\n# Load the tokenizer and model from Hugging Face\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\nmodel = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n\ndef embed_text(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n    outputs = model(**inputs)\n    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze()\n    return embeddings.detach().numpy().tolist()",
    "google_drive_upload.py": "from google.oauth2 import service_account\nfrom googleapiclient.discovery import build\nfrom googleapiclient.http import MediaFileUpload\n\ndef save_notes_to_drive(notes_text, filename=\"Generated_Notes.txt\", folder_id=None):\n    creds = service_account.Credentials.from_service_account_file('client_secrets.json')\n    service = build('drive', 'v3', credentials=creds)\n\n    # Save notes as a temporary file\n    with open(filename, 'w') as f:\n        f.write(notes_text)\n\n    # Define file metadata and include the folder ID if provided\n    file_metadata = {\n        'name': filename,\n        'mimeType': 'text/plain'\n    }\n    \n    if folder_id:\n        file_metadata['parents'] = [folder_id]  # Set the parent folder\n\n    media = MediaFileUpload(filename, mimetype='text/plain')\n\n    # Upload the file to Google Drive\n    file = service.files().create(\n        body=file_metadata,\n        media_body=media,\n        fields='id'\n    ).execute()\n\n    print(f\"File uploaded to Google Drive with ID: {file.get('id')}\")",
    "requirements.txt": "accelerate==1.0.0\naiohappyeyeballs==2.4.3\naiohttp==3.10.8\naiosignal==1.3.1\nannotated-types==0.7.0\nanyio==4.6.0\nattrs==24.2.0\nbeautifulsoup4==4.12.3\nblinker==1.8.2\nblis==1.0.1\ncatalogue==2.0.10\ncertifi==2024.8.30\ncharset-normalizer==3.3.2\nclick==8.1.7\ncloudpathlib==0.19.0\nconfection==0.1.5\ncymem==2.0.8\ndataclasses-json==0.6.7\ndatasets==3.0.1\ndateparser==1.2.0\nDeprecated==1.2.14\ndill==0.3.8\ndirtyjson==1.0.8\ndistro==1.9.0\nen_core_web_sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl#sha256=1932429db727d4bff3deed6b34cfc05df17794f4a52eeb26cf8928f7c1a0fb85\nfilelock==3.16.1\nfireworks-ai==0.15.4\nFlask==3.0.3\nfrozenlist==1.4.1\nfsspec==2024.6.1\ngreenlet==3.1.1\ngroq==0.11.0\ngrpcio==1.66.2\ngrpcio-tools==1.66.2\nh11==0.14.0\nh2==4.1.0\nhpack==4.0.0\nhttpcore==1.0.6\nhttpx==0.27.2\nhttpx-sse==0.4.0\nhuggingface-hub==0.25.1\nhyperframe==6.0.1\nidna==3.10\nInstructorEmbedding==1.0.1\nitsdangerous==2.2.0\nJinja2==3.1.4\njiter==0.5.0\njoblib==1.4.2\njsonpatch==1.33\njsonpointer==3.0.0\nlangchain==0.3.2\nlangchain-core==0.3.8\nlangchain-groq==0.2.0\nlangchain-text-splitters==0.3.0\nlangcodes==3.4.1\nlangsmith==0.1.131\nlanguage_data==1.2.0\nllama-cloud==0.1.2\nllama-index==0.11.17\nllama-index-agent-openai==0.3.4\nllama-index-cli==0.3.1\nllama-index-core==0.11.17\nllama-index-embeddings-huggingface==0.3.1\nllama-index-embeddings-instructor==0.2.1\nllama-index-embeddings-openai==0.2.5\nllama-index-indices-managed-llama-cloud==0.4.0\nllama-index-legacy==0.9.48.post3\nllama-index-llms-openai==0.2.13\nllama-index-multi-modal-llms-openai==0.2.2\nllama-index-program-openai==0.2.0\nllama-index-question-gen-openai==0.2.0\nllama-index-readers-file==0.2.2\nllama-index-readers-llama-parse==0.3.0\nllama-parse==0.5.7\nmarisa-trie==1.2.0\nmarkdown-it-py==3.0.0\nMarkupSafe==2.1.5\nmarshmallow==3.22.0\nmdurl==0.1.2\nminijinja==2.2.0\nmpmath==1.3.0\nmultidict==6.1.0\nmultiprocess==0.70.16\nmurmurhash==1.0.10\nmypy-extensions==1.0.0\nnest-asyncio==1.6.0\nnetworkx==3.3\nnltk==3.9.1\nnumpy==1.26.4\nopenai==1.51.0\norjson==3.10.7\npackaging==24.1\npandas==2.2.3\npillow==10.4.0\nportalocker==2.10.1\npreshed==3.0.9\nprotobuf==5.28.2\npsutil==6.0.0\npyarrow==17.0.0\npydantic==2.9.2\npydantic_core==2.23.4\nPygments==2.18.0\npypdf==4.3.1\npython-dateutil==2.9.0.post0\npython-dotenv==1.0.1\npytz==2024.2\nPyYAML==6.0.2\nqdrant-client==1.11.3\nregex==2024.9.11\nrequests==2.32.3\nrequests-toolbelt==1.0.0\nrich==13.9.2\nsafetensors==0.4.5\nscikit-learn==1.5.2\nscipy==1.14.1\nsentence-transformers==2.7.0\nsetuptools==75.1.0\nshellingham==1.5.4\nsix==1.16.0\nsmart-open==7.0.5\nsniffio==1.3.1\nsoupsieve==2.6\nspacy==3.8.2\nspacy-legacy==3.0.12\nspacy-loggers==1.0.5\nSQLAlchemy==2.0.35\nsrsly==2.4.8\nstriprtf==0.0.26\nsympy==1.13.3\ntenacity==8.5.0\nthinc==8.3.2\nthreadpoolctl==3.5.0\ntiktoken==0.8.0\ntokenizers==0.20.0\ntorch==2.4.1\ntqdm==4.66.5\ntransformers==4.45.2\ntyper==0.12.5\ntyping-inspect==0.9.0\ntyping_extensions==4.12.2\ntzdata==2024.2\ntzlocal==5.2\nurllib3==2.2.3\nwasabi==1.1.3\nweasel==0.4.1\nWerkzeug==3.0.4\nwrapt==1.16.0\nxxhash==3.5.0\nyarl==1.13.1\n",
    "send_zoom_message.py": "import os\nimport requests\nfrom dotenv import load_dotenv\n\n# Load environment variables\nload_dotenv()\n\ndef send_chat_to_zoom(message, payload):\n    \"\"\"\n    Sends a chat message to Zoom via the Zoom chat API.\n    \"\"\"\n    try:\n        url = \"https://api.zoom.us/v2/im/chat/messages\"\n        token = get_chatbot_token()\n        headers = {\n            \"Authorization\": f\"Bearer {token}\",\n            \"Content-Type\": \"application/json\"\n        }\n\n        data = {\n            \"robot_jid\": os.getenv(\"ZOOM_BOT_JID\"),\n            \"to_jid\": payload['toJid'],\n            \"user_jid\": payload['toJid'],\n            \"content\": {\n                \"head\": {\"text\": \"OpenAI Chatbot\"},\n                \"body\": [{\"type\": \"message\", \"text\": f\"Assistant: {message}\"}]\n            }\n        }\n\n        # Send the request\n        response = requests.post(url, json=data, headers=headers)\n        response.raise_for_status()\n        print(\"Successfully sent chat to Zoom.\")\n    except requests.exceptions.RequestException as e:\n        print(f\"Error sending chat to Zoom: {e}\")\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n\ndef get_chatbot_token():\n    \"\"\"\n    Retrieves the chatbot token using client credentials from the Zoom OAuth API.\n    \"\"\"\n    try:\n        url = \"https://zoom.us/oauth/token?grant_type=client_credentials\"\n        client_id = os.getenv(\"ZOOM_CLIENT_ID\")\n        client_secret = os.getenv(\"ZOOM_CLIENT_SECRET\")\n        \n        if not client_id or not client_secret:\n            raise ValueError(\"Missing Zoom client ID or client secret in environment variables.\")\n\n        headers = {\n            \"Authorization\": \"Basic \" + requests.auth._basic_auth_str(client_id, client_secret)\n        }\n\n        response = requests.post(url, headers=headers)\n        response.raise_for_status()\n\n        return response.json().get('access_token')\n    except requests.exceptions.RequestException as e:\n        print(f\"Error getting chatbot token from Zoom: {e}\")\n        raise\n    except Exception as e:\n        print(f\"Unexpected error when retrieving chatbot token: {e}\")\n        raise\n",
    "zoom_auth.py": "import os\nimport base64\nimport requests\nfrom dotenv import load_dotenv\n\n# Load environment variables\nload_dotenv()\n\ndef get_zoom_bot_token():\n    \"\"\"\n    Retrieves the Zoom bot token using client credentials from the Zoom OAuth API.\n    \"\"\"\n    client_id = os.getenv(\"ZOOM_CLIENT_ID\")\n    client_secret = os.getenv(\"ZOOM_CLIENT_SECRET\")\n    \n    # Check if client_id and client_secret are present\n    if not client_id or not client_secret:\n        print(\"Error: Missing Zoom client ID or client secret in environment variables.\")\n        return None\n\n    token_url = \"https://zoom.us/oauth/token?grant_type=client_credentials\"\n    \n    # Prepare the authorization header\n    auth_header = base64.b64encode(f\"{client_id}:{client_secret}\".encode()).decode()\n    headers = {\n        \"Authorization\": f\"Basic {auth_header}\"\n    }\n\n    try:\n        response = requests.post(token_url, headers=headers)\n        response.raise_for_status()\n        return response.json().get(\"access_token\")\n    except requests.exceptions.RequestException as e:\n        print(f\"Error getting Zoom bot token: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        return None\n",
    "zoom_webhook_handler.py": "import os\nimport requests\nimport base64\nfrom flask import jsonify\nfrom dotenv import load_dotenv\n\n# Load environment variables\nload_dotenv()\n\ndef handle_zoom_webhook(response, payload):\n    \"\"\"\n    Handles incoming requests from the Zoom webhook, generating a response\n    to be sent back to the Zoom chat.\n\n    :param response: Text response to be sent back to the Zoom chat\n    :param payload: JSON payload from the Zoom webhook, containing details like 'toJid' and 'accountId'\n    \"\"\"\n    zoom_bot_jid = os.getenv(\"ZOOM_BOT_JID\")\n    auth_token = get_zoom_bot_token()\n\n    # Check if the Zoom bot token was retrieved successfully\n    if not auth_token:\n        print(\"Error: Could not retrieve Zoom bot token.\")\n        return\n\n    # Check if zoom_bot_jid is set in the environment\n    if not zoom_bot_jid:\n        print(\"Error: ZOOM_BOT_JID environment variable not found.\")\n        return\n\n    # Construct the message payload\n    message_payload = {\n        \"robot_jid\": zoom_bot_jid,\n        \"to_jid\": payload.get(\"toJid\"),\n        \"user_jid\": payload.get(\"toJid\"),\n        \"account_id\": payload.get(\"accountId\"),\n        \"content\": {\n            \"head\": {\"text\": \"Meeting Insights\"},\n            \"body\": [\n                {\"type\": \"message\", \"text\": response}  # Inject the Qdrant response here\n            ]\n        }\n    }\n\n    headers = {\n        \"Authorization\": f\"Bearer {auth_token}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    zoom_url = \"https://api.zoom.us/v2/im/chat/messages\"\n\n    try:\n        resp = requests.post(zoom_url, headers=headers, json=message_payload)\n        resp.raise_for_status()\n        print(\"Message sent successfully to Zoom:\", resp.json())\n    except requests.exceptions.RequestException as e:\n        print(f\"Error sending message to Zoom: {e}\")\n        if resp.content:\n            print(\"Response content:\", resp.json())\n\ndef get_zoom_bot_token():\n    \"\"\"\n    Retrieves the Zoom bot token using client credentials.\n    \"\"\"\n    zoom_client_id = os.getenv(\"ZOOM_CLIENT_ID\")\n    zoom_client_secret = os.getenv(\"ZOOM_CLIENT_SECRET\")\n\n    # Validate environment variables\n    if not zoom_client_id or not zoom_client_secret:\n        print(\"Error: Missing ZOOM_CLIENT_ID or ZOOM_CLIENT_SECRET environment variables.\")\n        return None\n\n    auth_url = \"https://zoom.us/oauth/token?grant_type=client_credentials\"\n    headers = {\n        \"Authorization\": \"Basic \" + base64.b64encode(f\"{zoom_client_id}:{zoom_client_secret}\".encode()).decode()\n    }\n\n    try:\n        response = requests.post(auth_url, headers=headers)\n        response.raise_for_status()\n        return response.json().get(\"access_token\")\n    except requests.exceptions.RequestException as e:\n        print(f\"Error retrieving Zoom bot token: {e}\")\n        if response.content:\n            print(\"Response content:\", response.json())\n        return None\n",
    "transcripts/transcript_intro_to_ml.txt": "Lecture Title: Introduction to Machine Learning\nDate: October 10, 2024\nDuration: 45 minutes\nSpeaker: Professor Smith\n\nProfessor Smith:\n\u201cWelcome to today\u2019s lecture on Machine Learning. We'll start by defining what Machine Learning is and why it has become such an important field in technology today. In simple terms, Machine Learning is a subset of artificial intelligence that focuses on enabling machines to learn from data and make decisions or predictions based on that data.\n\nThere are three primary types of machine learning:\n\nSupervised Learning: This involves training a model on a labeled dataset, meaning that each example in the training data includes the correct answer. Think of it like having a teacher guiding the learning process.\nUnsupervised Learning: Here, we train the model on data without any labels. The model has to find patterns or structures on its own. An example of this is clustering, where the model groups data points with similar features.\nReinforcement Learning: This is a bit different. In reinforcement learning, an agent learns by interacting with an environment and receiving rewards or penalties based on its actions. This approach is often used in game AI and robotics.\nNow let\u2019s dive deeper into each type. We\u2019ll start with Supervised Learning. Imagine you\u2019re teaching a child to recognize objects. You show them a picture of a dog and say, \u2018This is a dog.\u2019 Over time, with enough examples, the child learns to identify a dog even if they haven\u2019t seen that specific dog before. In machine learning terms, we would call this \u2018training on labeled data.\u2019\n\nMoving on to Unsupervised Learning, this is like giving a child a box of mixed objects and asking them to sort them into groups. The child doesn\u2019t know what each object is called but can group them based on similar shapes, colors, or sizes. In machine learning, this is clustering, and it helps us find hidden patterns in data.\n\nFinally, Reinforcement Learning is similar to training a pet. If the pet performs a trick correctly, it gets a treat. If it doesn\u2019t, it gets no treat, or maybe even a scolding. Over time, the pet learns which actions are associated with rewards and which are not.\n\nLet\u2019s discuss some applications of these methods. For example, Supervised Learning is widely used in facial recognition systems. Unsupervised Learning is used in customer segmentation, where companies group customers based on purchasing behavior to tailor marketing strategies. Reinforcement Learning is popular in robotics, where robots learn to navigate environments or in complex games where AI can beat human players.\n\nTo conclude, Machine Learning allows us to create systems that improve automatically through experience. It has vast applications across industries, from healthcare to finance, and the demand for skilled professionals in this field continues to grow.\u201d"
}